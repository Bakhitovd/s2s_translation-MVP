# ACT MODE TODO — Web MVP EN↔RU Real-Time Speech→Speech

- [ ] Create `server/app.py` with FastAPI, static frontend mount, and `/ws/audio` WebSocket
- [ ] Implement WebSocket protocol: JSON control + binary PCM, segmentation, AST→TTS→resample→PCM out
- [ ] Update/extend `server/audio_util.py` with `resample_float32` and `float32_to_int16le_bytes`
- [ ] Verify/align `frontend/worklets/encoder.worklet.js` for 16 kHz mono Int16LE PCM framing
- [ ] Replace/update `frontend/app.js` for device selection, AudioWorklet, `/ws/audio` protocol, PCM playback
- [ ] Replace/update `frontend/index.html` for new controls, transcript panes, VU meter, output routing
- [ ] Add/verify minimal `frontend/styles.css` for layout
- [ ] Update `server/requirements.txt` and `docker/Dockerfile` for FastAPI, uvicorn, numpy<2, scipy, soundfile, pydub, torch pin, port 8000
- [ ] Test end-to-end: run server, open frontend, test mic/tab capture, streaming, transcripts, output device, latency
- [ ] Add metrics/backpressure: queue drops, `{type:"stats"}` events
- [ ] Update README with quick start and usage
